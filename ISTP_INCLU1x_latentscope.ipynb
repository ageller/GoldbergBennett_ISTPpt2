{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Bennett's Data\n",
    "\n",
    "`INCLU1x IF Responses - ALL RUNS 041924.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')  # Download the punkt tokenizer if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from latentscope_helper import latentscope_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and clean the data\n",
    "\n",
    "These next two cells only need to be run once.  (If rerunning this notebook, you can start after the next markdown cell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to True if you want to change the data the is used \n",
    "# (It takes some time to split the responses by sentences, so I will only do this once and then use that file late)\n",
    "read_in_original_data_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into sentences\n",
    "def split_into_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (read_in_original_data_file):\n",
    "    # read in the data\n",
    "    df = pd.read_excel(\"../../data/INCLU1x IF Responses - ALL RUNS 041924.xlsx\")\n",
    "    print(f\"length of original DataFrame = {len(df)}\")\n",
    "\n",
    "    # only take the columns we need and rename them to remove spaces and special characters\n",
    "    data_tmp = df[['ID#','Course Run','Student Response']].rename(columns = {'ID#':'ID','Course Run':'course_run','Student Response':'student_responses'})\n",
    "\n",
    "    # remove extra newlines, etc.\n",
    "    data_tmp['student_responses'] = data_tmp['student_responses'].str.replace('\\n', ' ')\n",
    "\n",
    "    # this phrase appears a lot; we should remove it\n",
    "    data_tmp['student_responses'] = data_tmp['student_responses'].str.replace('Inclusive teaching is important to me because','') \n",
    "    \n",
    "    # remove rows with short answers (otherwise the sentence finder might choke -- not sure why)\n",
    "    n_min = 5\n",
    "    data_tmp = data_tmp[data_tmp['student_responses'].str.split().str.len().gt(n_min)]  \n",
    "\n",
    "    # save to .csv file\n",
    "    data_tmp.to_csv(\"../../data/INCLU1x_IF_Responses_-_ALL_RUNS_041924_cleaned.csv\", index=False)\n",
    "\n",
    "    # split into sentences\n",
    "    data = pd.DataFrame(columns=data_tmp.columns)\n",
    "    for index, row in data_tmp.iterrows():\n",
    "        # Split the response into sentences\n",
    "        sentences = split_into_sentences(row['student_responses'])\n",
    "        \n",
    "        # Create a new row for each sentence and append it to the new DataFrame\n",
    "        for sentence in sentences:\n",
    "            new_row = row.copy()\n",
    "            new_row['student_responses'] = sentence\n",
    "            data = data._append(new_row, ignore_index=True)\n",
    "\n",
    "    # remove rows with short answers (again)\n",
    "    n_min = 5\n",
    "    data = data[data['student_responses'].str.split().str.len().gt(n_min)]  \n",
    "\n",
    "    print(f\"length of new DataFrame (after cleaning and sentence splitting) = {len(data)}\")\n",
    "\n",
    "    # Save the new DataFrame to a new file (since this takes a while to run)\n",
    "    data.to_csv(\"../../data/INCLU1x_IF_Responses_-_ALL_RUNS_041924_cleaned_split_into_sentences.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and run `latent-scope` using my Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I worry that splitting into sentences may not be ideal because some of the meaning of the answer is lost, but without splitting I might combine different themes\n",
    "data = pd.read_csv(\"../../data/INCLU1x_IF_Responses_-_ALL_RUNS_041924_cleaned_split_into_sentences.csv\")\n",
    "#data = pd.read_csv(\"../../data/INCLU1x_IF_Responses_-_ALL_RUNS_041924_cleaned.csv\")\n",
    "\n",
    "# initialize my helper object\n",
    "worker = latentscope_helper(\n",
    "    latent_scope_dir = \"../../latent-scope_data\", # directory where the latentscope files are stored\n",
    "    dataset_id = \"INCLU1x_IF_Responses_-_ALL_RUNS_041924\", # data set name, for the sub-directory name within latent_scope_dir for this project\n",
    "    data = data, # pandas DataFrame that contains the data to analyze\n",
    "    text_column = \"student_responses\", # response column name from data_file\n",
    "    scope_number = 'new', # number that will be appended to all latentscope files \n",
    "    remove_old_files = True, # set this to True if you want to clean the latent-scope directories and start fresh\n",
    "    imax = 50, # maximum number of scopes that it should search through\n",
    "    run_embedding = True, # whether to run the embedding step (and potentially remove previous files)\n",
    "    run_umap = True, # whether to run the umap step (and potentially remove previous files)\n",
    "    run_cluster = True, # whether to run the clustering step (and potentially remove previous files)\n",
    "    run_label = True, # whether to run the labeling step (and potentially remove previous files)\n",
    "    embedding_model_id = \"transformers-jinaai___jina-embeddings-v2-small-en\", # embeddings model name\n",
    "    embedding_n_dimensions = 1000, # number of dimensions for embedding.  reading the jina docs, they often use this number as an example for the number of dimensions (not sure this is a recommendation though)\n",
    "    umap_n_components = 3, # number of UMAP dimensions\n",
    "    umap_n_neighbors = 100, # \"controls how UMAP balances local versus global structure in the data.\" Larger values mean UMAP will look at larger distances for neighbors (15 is default)\n",
    "    umap_min_dist = 0, # \"controls how tightly UMAP is allowed to pack points together\" (default is 0.1)\n",
    "    cluster_samples = 5, # min_cluster_size in HDBSCAN : \"the smallest size grouping that you wish to consider a cluster\"\n",
    "    cluster_min_samples = 10, # min_samples in HDBSCAN : \"provide a measure of how conservative you want your clustering to be. The larger the value of min_samples you provide, the more conservative the clustering â€“ more points will be declared as noise, and clusters will be restricted to progressively more dense areas.\"\n",
    "    cluster_selection_epsilon =  0.05, # cluster_selection_epsilon in HDBSCAN : distance measure between clusters that \"ensures that clusters below the given threshold are not split up any further\"\n",
    "    chat_model_id = \"transformers-TinyLlama___TinyLlama-1.1B-Chat-v1.0\", # LLM to use for labeling the clusters\n",
    "    label_length = 10, # max length to tell the LLM to use when generating a given label (not always respected by the LLM!)\n",
    "    chat_model_instructions_before = \"Below is a list of items each starting with [item].  Each item is a response from a different person to a survey. These items all have a similar theme.  The list begins below.\", # string of text to provide the LLM as instructions before the list of cluster items is given\n",
    "    chat_model_instructions_after = \"That was the last item in the list.  Now return a concise label for the items in this list that describes the theme.  This label should not be fully verbatim text from any individual item.  Your label should contain no more than 10 words.\", # string of text to provide the LLM as instructions after the list of cluster items is given\n",
    "    scope_description = \"First full test with responses separated into sentences\", #label to give the scope (when using the latentscope server to view the data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run latent-scope (using the inputs from above)\n",
    "\n",
    "worker.run_embedding = False\n",
    "worker.run_umap = False\n",
    "\n",
    "worker.initialize_files_and_numbering()\n",
    "worker.initialize_latentscope()\n",
    "worker.run_latentscope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to plot a specific scope number, you can define it here (and you don't need to actually run latentscope in the previous cell)\n",
    "worker.scope_number = '001'\n",
    "worker.initialize_latentscope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the labels\n",
    "worker.print_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar chart of the labels\n",
    "f, ax = worker.create_bar_chart(filename = os.path.join('plots', worker.dataset_id + '_scope' + worker.scope_number + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Excel workbook to review the results\n",
    "# The first sheet will have the raw data.  \n",
    "# The second sheet will have a map between cluster label and sheet name.  \n",
    "# Subsequent sheets will be one per cluster containing the cluster data.\n",
    "data_raw = pd.read_excel(\"../../data/INCLU1x IF Responses - ALL RUNS 041924.xlsx\")\n",
    "# clean up the data for the output\n",
    "data_raw_sheet = pd.DataFrame()\n",
    "data_raw_sheet['ID'] = data_raw['ID#']\n",
    "data_raw_sheet['course_run'] = data_raw['Course Run']\n",
    "data_raw_sheet['unknown_question'] = data_raw['Student Response'] # I need to update this with the actual question\n",
    "\n",
    "worker.create_excel_workbook(data_raw_sheet, os.path.join('tables', worker.dataset_id + '_clusters_scope' + worker.scope_number + '.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics to assess the quality of this analysis\n",
    "\n",
    "Ideally, I would want to do this for a number of runs each changing some parameter and returning a different number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns inertia, Silhouette Coefficient, Calinski-Harabasz Index, Davies-Bouldin Index\n",
    "# - a lower inertia value is generally better\n",
    "# - a higher Silhouette Coefficient score relates to a model with better defined clusters. \n",
    "# - a higher Calinski-Harabasz score relates to a model with better defined clusters.\n",
    "# - a lower Davies-Bouldin index relates to a model with better separation between the clusters.\n",
    "worker.calculate_metrics('001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the server to investigate and visualize these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls.serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available models can be printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a list of possible embedding models\n",
    "# [m[\"id\"] for m in ls.models.get_embedding_model_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a list of available LLMS for labelling the clusters\n",
    "# [m[\"id\"] for m in ls.models.get_chat_model_list()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
